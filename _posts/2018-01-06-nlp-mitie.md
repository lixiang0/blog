---
title: "MITIE的简易教程之wordrep"
category: nlp
layout: post
tags: [mitie,nlp]
date: '2018-01-06 17:00:24'
---



[MITIE](https://github.com/mit-nlp/MITIE)是在dlib机器学习库之上开发的NLP工具包，支持分布式词嵌入和结构化SVM。提供[英语](https://github.com/mit-nlp/MITIE/releases/download/v0.4/MITIE-models-v0.2.tar.bz2)，[西班牙语](https://github.com/mit-nlp/MITIE/releases/download/v0.4/MITIE-models-v0.2-Spanish.zip)，[德语](https://github.com/mit-nlp/MITIE/releases/download/v0.4/MITIE-models-v0.2-German.tar.bz2)的预训练语言模型。MITIT核心代码使用C++编写，支持Python，R，Java,C,MATLAB的集成。

### 安装
MITIT的编译比较简单，按照下面的步骤就可以即可：
```
#clone 源码
git clone https://github.com/mit-nlp/MITIE.git
cd MITIE
python setup.py install
```
完成以上工具即可以在代码中```import```相应的```mitit module```:
```
from mitie import *
```

### 训练语言模型

执行:
```
cd MITIE/tools/wordrep
mkdir build
cd build
cmake ..
make
```
即可得到```wordrep```可执行文件,目录结构如下：
```
-MITIE/tools/wordrep/build
 - CMakeCache.txt  
 - CMakeFiles  
 - cmake_install.cmake  
 - dlib_build  
 - Makefile  
 - mitie_build  
 - wordrep

```

下面就可以使用```wordrep```训练自己的语言模型了:
```
cd ~
mkdir temp
cd temp
mv MITIE/tools/wordrep/build/wordrep .
mkdir zh
cp ~/text.txt ./zh
wordrep -e ./zh

```
上面的操作中，首先新建一个目录```temp```作为这次训练的工作目录，然后将```wordrep```拷贝到```temp```目录下。

然后新建目录```zh```用来存放训练的语料，语料的格式如下所示(一行一句，分词之后以空格隔开)：
```
你 可 不要 小看 我 
你 的 身高 是 多少
我 只有 二十厘米 高 ， 现在 还 在 买 半价票 呢 
你 有 多 高
我 个子 不高 呢 ， 只有 二十厘米 ， 出门 要 把 我 抱 在 怀里
```
训练完毕之后的目录结构为:
```
/temp
 - substring_set.dat
 - top_word_counts.dat
 - total_word_feature_extractor.dat
 - wordrep
 - zh/
 - substrings.txt
 - top_words.txt
 - word_morph_feature_extractor.dat
 - word_vects.dat
```

得到语言模型之后就可以测试了，下面是测试代码：

```
from mitie import *

print ("loading Total Word Feature Extractor...")

twfe = total_word_feature_extractor('zh/total_word_feature_extractor.dat')

# Get fingerprint of feature dictionary
print ("Fingerprint of feature dictionary", twfe.fingerprint)
print ()
# Get number of dimensions of feature vectors
print ("Number of dimensions of feature vectors", twfe.num_dimensions)
print ()
# Get number of words in the dictionary
print ("Number of words in the dictionary", twfe.num_words_in_dictionary)
print ()
# Get list of words in the dictionary
words=twfe.get_words_in_dictionary()
print ("First 10 words in dictionary", words[0:200])
print ()
# Get features for one word
feats = twfe.get_feature_vector("我")
print ("First 5 features of word 'home'", feats[0:])
# The total word feature extractor will generate feature vectors for words not
# in its dictionary as well.  It does this by looking at word morphology.  
feats = twfe.get_feature_vector("_word_not_in_dictionary_")
print ("First 5 features of word '_word_not_in_dictionary_'", feats[0:50])
```
输出为：
```
Number of dimensions of feature vectors 271
Number of words in the dictionary 2582
.....
...

```


